'use server';

import { getVoiceProperties, VoiceProperties } from '@/lib/voiceUtils';

interface TTSRequest {
    text: string;
    speakerId: string;
    emotion?: string;
    psychologicalState?: string;  // â˜… í•˜ì´í¼ ë¦¬ì–¼ë¦¬ì¦˜: ì‹¬ë¦¬ ìƒíƒœ
    physicalState?: string;        // â˜… í•˜ì´í¼ ë¦¬ì–¼ë¦¬ì¦˜: ì‹ ì²´ ìƒíƒœ
    overrideParams?: VoiceProperties; // â˜… DEV MODE: Manual Override
}

// 1. Preprocessor: Remove content inside parentheses (e.g. stage directions)
// â˜… í•˜ì´í¼ ë¦¬ì–¼ë¦¬ì¦˜: í˜¸í¡/ì˜ì„±ì–´ëŠ” ìœ ì§€í•˜ê³ , ì§€ë¬¸ë§Œ ì œê±°
function preprocessTextForTTS(text: string): string {
    // 1. Remove XML/HTML tags (e.g. <whisper>...</whisper> -> ...)
    const noTags = text.replace(/<[^>]*>/g, "");

    // 2. Remove long parentheses (Stage directions > 12 chars)
    // í˜¸í¡ í‘œí˜„ì€ ìœ ì§€: (í›„ìš°...), (ìœ½!), (í¥,) ë“±
    // ì§€ë¬¸ë§Œ ì œê±°: (ë¬´ê±°ìš´ í•œìˆ¨ì„ ì‰¬ë©°), (ê³ ê°œë¥¼ ëŒë¦¬ë©°) ë“±
    return noTags.replace(/\([^)]{12,}\)/g, ",").trim();
}

export async function generateSpeechAction({ text, speakerId, emotion, psychologicalState, physicalState, overrideParams }: TTSRequest): Promise<string | null> {
    if (!text || !speakerId) {
        console.warn("[TTS] Missing text or speakerId");
        return null;
    }

    const cleanText = preprocessTextForTTS(text);
    if (!cleanText) {
        console.warn("[TTS] Text became empty after preprocessing (only stage directions?)");
        return null;
    }

    // â˜… í•˜ì´í¼ ë¦¬ì–¼ë¦¬ì¦˜: ì‹¬ë¦¬/ì‹ ì²´ ìƒíƒœ ìš°ì„ , ì—†ìœ¼ë©´ ê°ì • ì‚¬ìš©
    const effectiveState = physicalState || psychologicalState || emotion || "ì¤‘ë¦½";

    // â˜… í•˜ì´í¼ ë¦¬ì–¼ë¦¬ì¦˜: ëŒ€ì‚¬ í…ìŠ¤íŠ¸ë„ í•¨ê»˜ ë¶„ì„í•˜ì—¬ speed/pitch ê²°ì • (Overrideê°€ ìˆìœ¼ë©´ ê·¸ê²ƒ ì‚¬ìš©)
    const props = overrideParams || await getVoiceProperties(effectiveState, cleanText);

    console.log(`[TTS] ğŸ­ Hyper-Realism Speech Generation`);
    console.log(`[TTS] Speaker: ${speakerId}, State: ${effectiveState}`);
    console.log(`[TTS] Original: "${text}" -> Clean: "${cleanText}"`);
    console.log(`[TTS] Properties: speed=${props.speed}, pitch=${props.pitch}`);

    const apiKey = process.env.VARCO_VOICE_API_KEY || process.env.VITE_VARCO_API_KEY || process.env.NEXT_PUBLIC_VARCO_VOICE_API_KEY;

    if (!apiKey) {
        console.error("[TTS] Missing VARCO_VOICE_API_KEY (or VITE_VARCO_API_KEY)");
        return null;
    }

    try {
        const startTime = Date.now();
        console.log(`[TTS] â±ï¸ Starting Varco API call...`);

        const response = await fetch('https://openapi.ai.nc.com/tts/standard/v1/api/synthesize', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'OPENAPI_KEY': apiKey
            },
            body: JSON.stringify({
                text: cleanText,
                voice: speakerId,
                language: 'korean',
                properties: {
                    speed: props.speed,
                    pitch: props.pitch
                }
            })
        });

        const apiTime = Date.now() - startTime;

        if (!response.ok) {
            console.error(`[TTS] âŒ Varco API Error (${apiTime}ms): ${response.status} ${response.statusText}`);
            const errText = await response.text();
            console.error(`[TTS] â””â”€ Details: ${errText}`);
            return null;
        }

        const data = await response.json();
        const totalTime = Date.now() - startTime;

        if (data.audio) {
            console.log(`[TTS] âœ… Success in ${totalTime}ms (API: ${apiTime}ms) - ${Math.round(data.audio.length / 1024)}KB audio`);
            return `data:audio/wav;base64,${data.audio}`;
        } else {
            console.error(`[TTS] âŒ No audio field in response (${totalTime}ms):`, Object.keys(data));
            return null;
        }

    } catch (error) {
        console.error("[TTS] âŒ Processing error:", error);
        return null;
    }
}
